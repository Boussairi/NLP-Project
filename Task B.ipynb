{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269740,"sourceType":"datasetVersion","datasetId":113003},{"sourceId":7880633,"sourceType":"datasetVersion","datasetId":4625271},{"sourceId":8065698,"sourceType":"datasetVersion","datasetId":4758500}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn import metrics\n\nimport transformers\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers import Trainer,TrainingArguments\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification\nfrom transformers import Trainer\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n\nimport matplotlib.pyplot as plt\nimport pickle\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T00:28:38.105734Z","iopub.execute_input":"2024-04-20T00:28:38.106193Z","iopub.status.idle":"2024-04-20T00:28:55.389708Z","shell.execute_reply.started":"2024-04-20T00:28:38.106155Z","shell.execute_reply":"2024-04-20T00:28:55.388727Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-20 00:28:50.477715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-20 00:28:50.477833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-20 00:28:50.608185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/deberta-embedding/DeBerta_embeddings.pkl\n/kaggle/input/sarcastic-comments-on-reddit/train-balanced-sarcasm.csv\n/kaggle/input/sarcasm-detection/task_B_En_test.csv\n/kaggle/input/sarcasm-detection/task_A_Ar_test.csv\n/kaggle/input/sarcasm-detection/train.En.csv\n/kaggle/input/sarcasm-detection/task_C_Ar_test.csv\n/kaggle/input/sarcasm-detection/arabic_task_a.csv\n/kaggle/input/sarcasm-detection/english_task_a.csv\n/kaggle/input/sarcasm-detection/arabic_task_c.csv\n/kaggle/input/sarcasm-detection/task_C_En_test.csv\n/kaggle/input/sarcasm-detection/task_A_En_test.csv\n/kaggle/input/sarcasm-detection/train.Ar.csv\n/kaggle/input/sarcasm-detection/english_task_c.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TASK B","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv(\"/kaggle/input/sarcasm-detection/train.En.csv\")\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:07:33.256772Z","iopub.execute_input":"2024-04-20T01:07:33.257334Z","iopub.status.idle":"2024-04-20T01:07:33.286362Z","shell.execute_reply.started":"2024-04-20T01:07:33.257301Z","shell.execute_reply":"2024-04-20T01:07:33.285144Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"(3468, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"train.dropna(subset=['tweet'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:07:40.534819Z","iopub.execute_input":"2024-04-20T01:07:40.535260Z","iopub.status.idle":"2024-04-20T01:07:40.544870Z","shell.execute_reply.started":"2024-04-20T01:07:40.535227Z","shell.execute_reply":"2024-04-20T01:07:40.543588Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"train['tweet'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:07:44.001986Z","iopub.execute_input":"2024-04-20T01:07:44.002767Z","iopub.status.idle":"2024-04-20T01:07:44.010580Z","shell.execute_reply.started":"2024-04-20T01:07:44.002728Z","shell.execute_reply":"2024-04-20T01:07:44.009412Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"### Obtention des embeddings de Bert","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nfrom torch import nn\nfrom transformers import Trainer,TrainingArguments\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel, DebertaV2Tokenizer\n\ndef bert(train_tweets, test_tweets):\n        # Initialize the BERT tokenizer\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', num_labels=2,\n                                                loss_function_params={\"weight\": [0.75, 0.25]})\n        \n        # Tokenize the input tweets and pad/truncate them to a maximum length of 512 tokens\n        train_encodings = tokenizer(train_tweets, padding=True, truncation=True, max_length=512)\n        test_encodings = tokenizer(test_tweets, padding=True, truncation=True, max_length=512)\n\n\n        # Convert the encodings to tensors\n        input_ids_train = torch.tensor(train_encodings['input_ids'])\n        attention_mask_train = torch.tensor(train_encodings['attention_mask'])\n        input_ids_test = torch.tensor(test_encodings['input_ids'])\n        attention_mask_test = torch.tensor(test_encodings['attention_mask'])\n\n        # Load the pre-trained BERT model\n        model = BertModel.from_pretrained('bert-base-uncased')\n\n        # Pass the tokenized input through the model\n        with torch.no_grad():\n            outputs_train = model(input_ids=input_ids_train, attention_mask=attention_mask_train)\n            outputs_test = model(input_ids=input_ids_test, attention_mask=attention_mask_test)\n\n        # Extract the embeddings from the model's output\n        embeddings_train = outputs_train.last_hidden_state\n        embeddings_test = outputs_test.last_hidden_state\n\n        return tokenizer, embeddings_train, embeddings_test","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:40:14.462122Z","iopub.execute_input":"2024-04-20T00:40:14.463042Z","iopub.status.idle":"2024-04-20T00:40:14.480204Z","shell.execute_reply.started":"2024-04-20T00:40:14.462995Z","shell.execute_reply":"2024-04-20T00:40:14.479026Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/sarcasm-detection/task_A_En_test.csv\")\ntest","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:44:53.308551Z","iopub.execute_input":"2024-04-20T00:44:53.309009Z","iopub.status.idle":"2024-04-20T00:44:53.341653Z","shell.execute_reply.started":"2024-04-20T00:44:53.308973Z","shell.execute_reply":"2024-04-20T00:44:53.340432Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                                   text  sarcastic\n0     Size on the the Toulouse team, That pack is mo...          0\n1                                              Pinball!          0\n2     So the Scottish Government want people to get ...          1\n3     villainous pro tip : change the device name on...          0\n4                       I would date any of these men ü•∫          0\n...                                                 ...        ...\n1395  I‚Äôve just seen this and felt it deserved a Ret...          0\n1396               Omg how an earth is that a pen !!! ü§°          0\n1397          Bringing Kanye and drake to a tl near you          0\n1398  I love it when women are referred to as \"girl ...          1\n1399  The fact that people still don't get that you ...          1\n\n[1400 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sarcastic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Size on the the Toulouse team, That pack is mo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pinball!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>So the Scottish Government want people to get ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>villainous pro tip : change the device name on...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I would date any of these men ü•∫</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1395</th>\n      <td>I‚Äôve just seen this and felt it deserved a Ret...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1396</th>\n      <td>Omg how an earth is that a pen !!! ü§°</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1397</th>\n      <td>Bringing Kanye and drake to a tl near you</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1398</th>\n      <td>I love it when women are referred to as \"girl ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1399</th>\n      <td>The fact that people still don't get that you ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1400 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_tweets = train['tweet'].values.tolist()\ntrain_labels = train['sarcastic'].values.tolist()\ntest_tweets = test['text'].values.tolist()\ntest_labels = test['sarcastic'].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:45:05.782384Z","iopub.execute_input":"2024-04-20T00:45:05.782836Z","iopub.status.idle":"2024-04-20T00:45:05.790082Z","shell.execute_reply.started":"2024-04-20T00:45:05.782802Z","shell.execute_reply":"2024-04-20T00:45:05.788694Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"tokenizer, train_embeddings, test_embeddings = bert(train_tweets, test_tweets)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:47:04.668035Z","iopub.execute_input":"2024-04-20T00:47:04.668808Z","iopub.status.idle":"2024-04-20T01:00:42.970359Z","shell.execute_reply.started":"2024-04-20T00:47:04.668765Z","shell.execute_reply":"2024-04-20T01:00:42.969108Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Convertir les tensors d'embeddings en tableaux numpy\nembeddings_train_np = train_embeddings.view(train_embeddings.size(0), -1).numpy()\n# Cr√©er une liste pour stocker les donn√©es\ndf1 = []\n# It√©rer sur chaque embedding et son label correspondant\nfor emb, label in zip(embeddings_train_np, train_labels):\n    # Ajouter une nouvelle ligne avec l'embedding et le label correspondant\n    df1.append({'tweet_embedding': emb, 'label': label})\n# Cr√©er le DataFrame √† partir de la liste de dictionnaires\ntrainset = pd.DataFrame(df1)\n# V√©rifier la forme du DataFrame\nprint(trainset.shape)\ntrainset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:01:48.009297Z","iopub.execute_input":"2024-04-20T01:01:48.010194Z","iopub.status.idle":"2024-04-20T01:01:48.040934Z","shell.execute_reply.started":"2024-04-20T01:01:48.010159Z","shell.execute_reply":"2024-04-20T01:01:48.039820Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"(3467, 2)\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                     tweet_embedding  label\n0  [0.19620167, 0.27427486, -0.12497724, -0.27851...      1\n1  [0.4314823, 0.42537883, 0.24392822, -0.3590437...      1\n2  [0.45887697, 0.07722696, -0.10633854, 0.145102...      1\n3  [0.054374322, 0.16270761, 0.12705112, -0.06395...      1\n4  [-0.015105082, 0.4109176, -0.044817008, 0.0373...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_embedding</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.19620167, 0.27427486, -0.12497724, -0.27851...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.4314823, 0.42537883, 0.24392822, -0.3590437...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.45887697, 0.07722696, -0.10633854, 0.145102...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.054374322, 0.16270761, 0.12705112, -0.06395...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.015105082, 0.4109176, -0.044817008, 0.0373...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## preparation des donnees","metadata":{}},{"cell_type":"code","source":"df = train[['tweet','sarcasm','irony','satire','understatement','overstatement','rhetorical_question']]","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:09:52.711394Z","iopub.execute_input":"2024-04-20T01:09:52.711777Z","iopub.status.idle":"2024-04-20T01:09:52.718747Z","shell.execute_reply.started":"2024-04-20T01:09:52.711749Z","shell.execute_reply":"2024-04-20T01:09:52.717562Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:09:53.045496Z","iopub.execute_input":"2024-04-20T01:09:53.046599Z","iopub.status.idle":"2024-04-20T01:09:53.068810Z","shell.execute_reply.started":"2024-04-20T01:09:53.046565Z","shell.execute_reply":"2024-04-20T01:09:53.067745Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"                                                  tweet  sarcasm  irony  \\\n0     The only thing I got from college is a caffein...      0.0    1.0   \n1     I love it when professors draw a big question ...      1.0    0.0   \n2     Remember the hundred emails from companies whe...      0.0    1.0   \n3     Today my pop-pop told me I was not ‚Äúforced‚Äù to...      1.0    0.0   \n4     @VolphanCarol @littlewhitty @mysticalmanatee I...      1.0    0.0   \n...                                                 ...      ...    ...   \n3463  The population spike in Chicago in 9 months is...      NaN    NaN   \n3464  You'd think in the second to last English clas...      NaN    NaN   \n3465  I‚Äôm finally surfacing after a holiday to Scotl...      NaN    NaN   \n3466  Couldn't be prouder today. Well done to every ...      NaN    NaN   \n3467  Overheard as my 13 year old games with a frien...      NaN    NaN   \n\n      satire  understatement  overstatement  rhetorical_question  \n0        0.0             0.0            0.0                  0.0  \n1        0.0             0.0            0.0                  0.0  \n2        0.0             0.0            0.0                  0.0  \n3        0.0             0.0            0.0                  0.0  \n4        0.0             0.0            0.0                  0.0  \n...      ...             ...            ...                  ...  \n3463     NaN             NaN            NaN                  NaN  \n3464     NaN             NaN            NaN                  NaN  \n3465     NaN             NaN            NaN                  NaN  \n3466     NaN             NaN            NaN                  NaN  \n3467     NaN             NaN            NaN                  NaN  \n\n[3467 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sarcasm</th>\n      <th>irony</th>\n      <th>satire</th>\n      <th>understatement</th>\n      <th>overstatement</th>\n      <th>rhetorical_question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The only thing I got from college is a caffein...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I love it when professors draw a big question ...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Remember the hundred emails from companies whe...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3463</th>\n      <td>The population spike in Chicago in 9 months is...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3464</th>\n      <td>You'd think in the second to last English clas...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3465</th>\n      <td>I‚Äôm finally surfacing after a holiday to Scotl...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3466</th>\n      <td>Couldn't be prouder today. Well done to every ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>Overheard as my 13 year old games with a frien...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3467 rows √ó 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"trainset","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:10:32.548422Z","iopub.execute_input":"2024-04-20T01:10:32.549679Z","iopub.status.idle":"2024-04-20T01:10:32.579119Z","shell.execute_reply.started":"2024-04-20T01:10:32.549627Z","shell.execute_reply":"2024-04-20T01:10:32.577937Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                                        tweet_embedding  label\n0     [0.19620167, 0.27427486, -0.12497724, -0.27851...      1\n1     [0.4314823, 0.42537883, 0.24392822, -0.3590437...      1\n2     [0.45887697, 0.07722696, -0.10633854, 0.145102...      1\n3     [0.054374322, 0.16270761, 0.12705112, -0.06395...      1\n4     [-0.015105082, 0.4109176, -0.044817008, 0.0373...      1\n...                                                 ...    ...\n3462  [0.17678487, -0.047839645, 0.25036606, -0.0831...      0\n3463  [0.26493683, 0.28706124, -0.35916415, -0.27260...      0\n3464  [-0.003417347, -0.20984395, 0.22559112, -0.539...      0\n3465  [-0.037949387, -0.21413586, 0.20614852, -0.175...      0\n3466  [0.17316444, 0.00942028, 0.5548433, -0.0170429...      0\n\n[3467 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_embedding</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.19620167, 0.27427486, -0.12497724, -0.27851...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.4314823, 0.42537883, 0.24392822, -0.3590437...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.45887697, 0.07722696, -0.10633854, 0.145102...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.054374322, 0.16270761, 0.12705112, -0.06395...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.015105082, 0.4109176, -0.044817008, 0.0373...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3462</th>\n      <td>[0.17678487, -0.047839645, 0.25036606, -0.0831...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3463</th>\n      <td>[0.26493683, 0.28706124, -0.35916415, -0.27260...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3464</th>\n      <td>[-0.003417347, -0.20984395, 0.22559112, -0.539...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3465</th>\n      <td>[-0.037949387, -0.21413586, 0.20614852, -0.175...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3466</th>\n      <td>[0.17316444, 0.00942028, 0.5548433, -0.0170429...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3467 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"newdf = pd.concat([trainset[\"tweet_embedding\"],df[['sarcasm','irony','satire','understatement','overstatement','rhetorical_question']]], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:12:20.513450Z","iopub.execute_input":"2024-04-20T01:12:20.514324Z","iopub.status.idle":"2024-04-20T01:12:20.526014Z","shell.execute_reply.started":"2024-04-20T01:12:20.514292Z","shell.execute_reply":"2024-04-20T01:12:20.524825Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"newdf","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:12:21.107022Z","iopub.execute_input":"2024-04-20T01:12:21.107990Z","iopub.status.idle":"2024-04-20T01:12:21.144338Z","shell.execute_reply.started":"2024-04-20T01:12:21.107957Z","shell.execute_reply":"2024-04-20T01:12:21.143083Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"                                        tweet_embedding  sarcasm  irony  \\\n0     [0.19620167, 0.27427486, -0.12497724, -0.27851...      0.0    1.0   \n1     [0.4314823, 0.42537883, 0.24392822, -0.3590437...      1.0    0.0   \n2     [0.45887697, 0.07722696, -0.10633854, 0.145102...      0.0    1.0   \n3     [0.054374322, 0.16270761, 0.12705112, -0.06395...      1.0    0.0   \n4     [-0.015105082, 0.4109176, -0.044817008, 0.0373...      1.0    0.0   \n...                                                 ...      ...    ...   \n3463  [0.26493683, 0.28706124, -0.35916415, -0.27260...      NaN    NaN   \n3464  [-0.003417347, -0.20984395, 0.22559112, -0.539...      NaN    NaN   \n3465  [-0.037949387, -0.21413586, 0.20614852, -0.175...      NaN    NaN   \n3466  [0.17316444, 0.00942028, 0.5548433, -0.0170429...      NaN    NaN   \n3467                                                NaN      NaN    NaN   \n\n      satire  understatement  overstatement  rhetorical_question  \n0        0.0             0.0            0.0                  0.0  \n1        0.0             0.0            0.0                  0.0  \n2        0.0             0.0            0.0                  0.0  \n3        0.0             0.0            0.0                  0.0  \n4        0.0             0.0            0.0                  0.0  \n...      ...             ...            ...                  ...  \n3463     NaN             NaN            NaN                  NaN  \n3464     NaN             NaN            NaN                  NaN  \n3465     NaN             NaN            NaN                  NaN  \n3466     NaN             NaN            NaN                  NaN  \n3467     NaN             NaN            NaN                  NaN  \n\n[3468 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_embedding</th>\n      <th>sarcasm</th>\n      <th>irony</th>\n      <th>satire</th>\n      <th>understatement</th>\n      <th>overstatement</th>\n      <th>rhetorical_question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.19620167, 0.27427486, -0.12497724, -0.27851...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.4314823, 0.42537883, 0.24392822, -0.3590437...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.45887697, 0.07722696, -0.10633854, 0.145102...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.054374322, 0.16270761, 0.12705112, -0.06395...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.015105082, 0.4109176, -0.044817008, 0.0373...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3463</th>\n      <td>[0.26493683, 0.28706124, -0.35916415, -0.27260...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3464</th>\n      <td>[-0.003417347, -0.20984395, 0.22559112, -0.539...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3465</th>\n      <td>[-0.037949387, -0.21413586, 0.20614852, -0.175...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3466</th>\n      <td>[0.17316444, 0.00942028, 0.5548433, -0.0170429...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3468 rows √ó 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"newdf = newdf.dropna()\nnewdf = newdf.reset_index(drop = True)\nnewdf","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:12:30.528085Z","iopub.execute_input":"2024-04-20T01:12:30.529261Z","iopub.status.idle":"2024-04-20T01:12:30.574799Z","shell.execute_reply.started":"2024-04-20T01:12:30.529212Z","shell.execute_reply":"2024-04-20T01:12:30.573711Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"                                       tweet_embedding  sarcasm  irony  \\\n0    [0.19620167, 0.27427486, -0.12497724, -0.27851...      0.0    1.0   \n1    [0.4314823, 0.42537883, 0.24392822, -0.3590437...      1.0    0.0   \n2    [0.45887697, 0.07722696, -0.10633854, 0.145102...      0.0    1.0   \n3    [0.054374322, 0.16270761, 0.12705112, -0.06395...      1.0    0.0   \n4    [-0.015105082, 0.4109176, -0.044817008, 0.0373...      1.0    0.0   \n..                                                 ...      ...    ...   \n862  [0.042694278, 0.28696677, 0.13154635, -0.12147...      1.0    0.0   \n863  [-0.13148308, 0.085815996, 0.23147838, -0.2539...      1.0    0.0   \n864  [0.38188905, -0.022620806, -0.15177612, -0.086...      0.0    1.0   \n865  [0.21844749, -0.3984793, -0.07088673, 0.154293...      1.0    0.0   \n866  [0.10106372, 0.14415403, -0.2805059, -0.585630...      1.0    0.0   \n\n     satire  understatement  overstatement  rhetorical_question  \n0       0.0             0.0            0.0                  0.0  \n1       0.0             0.0            0.0                  0.0  \n2       0.0             0.0            0.0                  0.0  \n3       0.0             0.0            0.0                  0.0  \n4       0.0             0.0            0.0                  0.0  \n..      ...             ...            ...                  ...  \n862     0.0             0.0            0.0                  1.0  \n863     0.0             0.0            0.0                  1.0  \n864     0.0             0.0            0.0                  0.0  \n865     0.0             0.0            0.0                  0.0  \n866     0.0             0.0            0.0                  0.0  \n\n[867 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_embedding</th>\n      <th>sarcasm</th>\n      <th>irony</th>\n      <th>satire</th>\n      <th>understatement</th>\n      <th>overstatement</th>\n      <th>rhetorical_question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.19620167, 0.27427486, -0.12497724, -0.27851...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.4314823, 0.42537883, 0.24392822, -0.3590437...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.45887697, 0.07722696, -0.10633854, 0.145102...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.054374322, 0.16270761, 0.12705112, -0.06395...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.015105082, 0.4109176, -0.044817008, 0.0373...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>862</th>\n      <td>[0.042694278, 0.28696677, 0.13154635, -0.12147...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>863</th>\n      <td>[-0.13148308, 0.085815996, 0.23147838, -0.2539...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>[0.38188905, -0.022620806, -0.15177612, -0.086...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>[0.21844749, -0.3984793, -0.07088673, 0.154293...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>866</th>\n      <td>[0.10106372, 0.14415403, -0.2805059, -0.585630...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>867 rows √ó 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_melted = pd.melt(newdf, id_vars=['tweet_embedding'], value_vars=['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], var_name='category', value_name='value')\n\n# Filtrer les lignes o√π la valeur est 1.0, car cela indique la cat√©gorie active\ndf_melted = df_melted[df_melted['value'] == 1.0]\n\n# Supprimer la colonne 'value' car elle n'est plus n√©cessaire\ndf_melted = df_melted.drop('value', axis=1)\n\n# Renommer la colonne 'category' si n√©cessaire\ndf_melted.rename(columns={'category': 'category_name'}, inplace=True)\n\ndf_melted.reset_index(drop = True)\n\ndf_melted","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:14:35.640349Z","iopub.execute_input":"2024-04-20T01:14:35.641278Z","iopub.status.idle":"2024-04-20T01:14:35.681215Z","shell.execute_reply.started":"2024-04-20T01:14:35.641233Z","shell.execute_reply":"2024-04-20T01:14:35.679981Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"                                        tweet_embedding        category_name\n1     [0.4314823, 0.42537883, 0.24392822, -0.3590437...              sarcasm\n3     [0.054374322, 0.16270761, 0.12705112, -0.06395...              sarcasm\n4     [-0.015105082, 0.4109176, -0.044817008, 0.0373...              sarcasm\n7     [-0.27869692, 0.31939417, 0.30761528, -0.71344...              sarcasm\n8     [-0.18095784, -0.2820461, 0.49480957, 0.167509...              sarcasm\n...                                                 ...                  ...\n5187  [0.15654793, 0.18364778, 0.059557784, -0.13280...  rhetorical_question\n5194  [0.13905942, -0.01920496, 0.029426834, -0.0493...  rhetorical_question\n5195  [0.033044245, 0.105464295, 0.1315186, -0.23984...  rhetorical_question\n5197  [0.042694278, 0.28696677, 0.13154635, -0.12147...  rhetorical_question\n5198  [-0.13148308, 0.085815996, 0.23147838, -0.2539...  rhetorical_question\n\n[1044 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_embedding</th>\n      <th>category_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>[0.4314823, 0.42537883, 0.24392822, -0.3590437...</td>\n      <td>sarcasm</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.054374322, 0.16270761, 0.12705112, -0.06395...</td>\n      <td>sarcasm</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.015105082, 0.4109176, -0.044817008, 0.0373...</td>\n      <td>sarcasm</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[-0.27869692, 0.31939417, 0.30761528, -0.71344...</td>\n      <td>sarcasm</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[-0.18095784, -0.2820461, 0.49480957, 0.167509...</td>\n      <td>sarcasm</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5187</th>\n      <td>[0.15654793, 0.18364778, 0.059557784, -0.13280...</td>\n      <td>rhetorical_question</td>\n    </tr>\n    <tr>\n      <th>5194</th>\n      <td>[0.13905942, -0.01920496, 0.029426834, -0.0493...</td>\n      <td>rhetorical_question</td>\n    </tr>\n    <tr>\n      <th>5195</th>\n      <td>[0.033044245, 0.105464295, 0.1315186, -0.23984...</td>\n      <td>rhetorical_question</td>\n    </tr>\n    <tr>\n      <th>5197</th>\n      <td>[0.042694278, 0.28696677, 0.13154635, -0.12147...</td>\n      <td>rhetorical_question</td>\n    </tr>\n    <tr>\n      <th>5198</th>\n      <td>[-0.13148308, 0.085815996, 0.23147838, -0.2539...</td>\n      <td>rhetorical_question</td>\n    </tr>\n  </tbody>\n</table>\n<p>1044 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"target_mapping = {\n    'sarcasm': 0,\n    'irony': 1,\n    'satire': 2,\n    'understatement': 3,\n    'overstatement': 4,\n    'rhetorical_question': 5\n}\n\n# Appliquer le mapping\ndf_melted['category_name'] = df_melted['category_name'].map(target_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:15:43.032602Z","iopub.execute_input":"2024-04-20T01:15:43.033679Z","iopub.status.idle":"2024-04-20T01:15:43.041490Z","shell.execute_reply.started":"2024-04-20T01:15:43.033640Z","shell.execute_reply":"2024-04-20T01:15:43.040133Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"X = np.array(df_melted['tweet_embedding'].tolist(), dtype=np.float32)\ny = np.array(df_melted['category_name'], dtype=np.int64)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:28:01.712801Z","iopub.execute_input":"2024-04-20T01:28:01.713381Z","iopub.status.idle":"2024-04-20T01:28:01.974365Z","shell.execute_reply.started":"2024-04-20T01:28:01.713344Z","shell.execute_reply":"2024-04-20T01:28:01.973353Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:30:41.102167Z","iopub.execute_input":"2024-04-20T01:30:41.103250Z","iopub.status.idle":"2024-04-20T01:30:41.111313Z","shell.execute_reply.started":"2024-04-20T01:30:41.103214Z","shell.execute_reply":"2024-04-20T01:30:41.110024Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"array([[ 0.16821772,  0.03308778, -0.11634181, ..., -0.08379351,\n        -0.13654253, -0.18546596],\n       [ 0.3210809 ,  0.15854144,  0.06700815, ...,  0.23087965,\n         0.21148846, -0.3702405 ],\n       [ 0.08154248, -0.01922362,  0.1047432 , ...,  0.16918296,\n         0.16014515, -0.04929092],\n       ...,\n       [-0.02222835,  0.5061802 , -0.05233792, ..., -0.23268466,\n         0.04546177,  0.17783585],\n       [ 0.21638337,  0.01808404, -0.08684637, ...,  0.08150347,\n         0.01344071, -0.33489802],\n       [ 0.01412205,  0.01153579,  0.1329101 , ..., -0.00706784,\n         0.16417462, -0.16774863]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Entrainnement de SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\n\n# Standardisation des donn√©es\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Entra√Ænement du mod√®le SVM\nsvm = SVC(kernel='rbf', C=1, gamma='auto')\nsvm.fit(X_train_scaled, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:33:09.899813Z","iopub.execute_input":"2024-04-20T01:33:09.900836Z","iopub.status.idle":"2024-04-20T01:34:07.743913Z","shell.execute_reply.started":"2024-04-20T01:33:09.900802Z","shell.execute_reply":"2024-04-20T01:34:07.742866Z"},"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"SVC(C=1, gamma='auto')","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"X_test_scaled = scaler.transform(X_test)\ny_pred = clf.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred)\nf1score = f1_score (y_test, y_pred, average='weighted')\n\nprint(\"Exactitude (Accuracy) :\", accuracy)\nprint(\"F1-score:\", f1score)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T01:49:44.027162Z","iopub.execute_input":"2024-04-20T01:49:44.028129Z","iopub.status.idle":"2024-04-20T01:49:45.178122Z","shell.execute_reply.started":"2024-04-20T01:49:44.028091Z","shell.execute_reply":"2024-04-20T01:49:45.176566Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Exactitude (Accuracy) : 0.3923444976076555\nF1-score: 0.4483926421806414\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}