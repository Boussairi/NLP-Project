{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create process using 'C:\\Users\\BOUFARIS JINANE\\anaconda3\\python.exe \"C:\\Users\\BOUFARIS JINANE\\anaconda3\\Scripts\\pip-script.py\" install alphabet_detector'\n",
      "Unable to create process using 'C:\\Users\\BOUFARIS JINANE\\anaconda3\\python.exe \"C:\\Users\\BOUFARIS JINANE\\anaconda3\\Scripts\\pip-script.py\" install arabert'\n"
     ]
    }
   ],
   "source": [
    "!pip install alphabet_detector\n",
    "!pip install arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.ArabicTweets.ArabertLM import ArabertLM \n",
    "from Models.ArabicTweets.CNN import CNN \n",
    "from Models.ArabicTweets.LogisticRegression import LogisticRegression\n",
    "from Models.ArabicTweets.MarberLM import MarberLM\n",
    "from Models.ArabicTweets.RNN import RNN\n",
    "from Models.ArabicTweets.SVM import SVM\n",
    "from prog.ArabicTextCleaning import ArabicTextCleaning\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'train/train.Ar.csv'\n",
    "ArbTc = ArabicTextCleaning(path)\n",
    "train_data = ArbTc.load_data()\n",
    "train_data['text']= train_data['text'].apply(ArbTc.clean_doc)\n",
    "train_data = ArbTc.drop_columns(train_data)\n",
    "ArbTc.translate_dialect(train_data)\n",
    "train_data_original = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Arabert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arabert = ArabertLM()\n",
    "train_data = train_data_original.copy()\n",
    "train_data['text_embeddings']= train_data['text'].apply(Arabert.generate_embeddings)\n",
    "train_data.drop(['text'], axis =1)\n",
    "embeddings_list = train_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "y = np.array(train_data['sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ArbTc.split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr = LogisticRegression()\n",
    "y_pred = Lr.generatePrediction(X_train, y_train, X_test)\n",
    "accuracy, f1 = Lr.evaluateModel(y_pred, y_test)\n",
    "print(\"Accuracy of Logistic REgression using Arabert embeddings:\", accuracy)\n",
    "print(\"f1 score of Logistic REgression using Arabert embeddings:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM()\n",
    "y_pred = svm.generatePredictions(X_train, y_train, X_test)\n",
    "accuracy, f1 = svm.evaluate_model(y_pred, y_test)\n",
    "print(\"Accuracy of SVM using Arabert embeddings:\", accuracy)\n",
    "print(\"f1 score of SVM using Arabert embeddings:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "rnn_model = rnn.configModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = train_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history = rnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "y_pred = rnn.predict(X_test, rnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = rnn.evaluateRNN(X_test, y_test, y_pred, rnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "rnn.plotTrainingHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification usinc CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "input_shape = X_train.shape[1:]\n",
    "cnn_model = cnn.configModel(input_shape)\n",
    "history2 = cnn_model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)\n",
    "y_pred = cnn.predict(X_test, cnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = cnn.evaluateCNN(X_test, y_test, y_pred, cnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "cnn.plotTrainingHistory(history2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Marbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Marbert = MarberLM()\n",
    "train_data = train_data_original.copy()\n",
    "train_data['text_embeddings']= train_data['text'].apply(Marbert.generate_embeddings)\n",
    "train_data.drop(['text'], axis =1)\n",
    "embeddings_list = train_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "y = np.array(train_data['sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ArbTc.split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr = LogisticRegression()\n",
    "y_pred = Lr.generatePrediction(X_train, y_train, X_test)\n",
    "accuracy, f1 = Lr.evaluateModel(y_pred, y_test)\n",
    "print(\"Accuracy of Logistic REgression using MArabert embeddings:\", accuracy)\n",
    "print(\"f1 score of Logistic REgression using MArabert embeddings:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM()\n",
    "y_pred = svm.generatePredictions(X_train, y_train, X_test)\n",
    "accuracy, f1 = svm.evaluate_model(y_pred, y_test)\n",
    "print(\"Accuracy of SVM using Arabert embeddings:\", accuracy)\n",
    "print(\"f1 score of SVM using Arabert embeddings:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "rnn_model = rnn.configModel()\n",
    "embeddings_list = train_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history3 = rnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "y_pred = rnn.predict(X_test, rnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = rnn.evaluateRNN(X_test, y_test, y_pred, rnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "rnn.plotTrainingHistory(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "input_shape = X_train.shape[1:]\n",
    "cnn_model = cnn.configModel(input_shape)\n",
    "history4 = cnn_model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)\n",
    "y_pred = cnn.predict(X_test, cnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = cnn.evaluateCNN(X_test, y_test, y_pred, cnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "cnn.plotTrainingHistory(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'train/data_for_augmantation.csv'\n",
    "data_for_augm = ArbTc.load_data()\n",
    "data_for_augm = data_for_augm.drop(['id', 'rephrase' ,'dialect'], axis =1)\n",
    "data_for_augm.rename(columns={'Texte_traduit': 'text'}, inplace=True)\n",
    "data_for_augm['text_embeddings']= data_for_augm['text'].apply(Marbert.generate_embeddings)\n",
    "\n",
    "data_for_augm = data_for_augm.drop(['text'], axis =1)\n",
    "\n",
    "augmented_data = pd.concat([train_data, data_for_augm], axis=0)\n",
    "\n",
    "augmented_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_list = augmented_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "y = np.array(augmented_data['sarcastic'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr = LogisticRegression()\n",
    "y_pred = Lr.generatePrediction(X_train, y_train, X_test)\n",
    "accuracy, f1 = Lr.evaluateModel(y_pred, y_test)\n",
    "print(\"Accuracy of Logistic REgression using Marbert embeddings with augmented data:\", accuracy)\n",
    "print(\"f1 score of Logistic REgression using Marbert embeddings with augmented data:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm = SVM()\n",
    "y_pred = svm.generatePredictions(X_train, y_train, X_test)\n",
    "accuracy, f1 = svm.evaluate_model(y_pred, y_test)\n",
    "print(\"Accuracy of SVM using using Marbert embeddings with augmented data:\", accuracy)\n",
    "print(\"f1 score of SVM using using Marbert embeddings with augmented data:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "rnn_model = rnn.configModel()\n",
    "embeddings_list = train_data['text_embeddings'].tolist()\n",
    "X = [embedding[0] for embedding in embeddings_list]\n",
    "X_np = [np.array(embedding) for embedding in X]\n",
    "\n",
    "max_length = max(len(embedding) for embedding in X_np)\n",
    "X = pad_sequences(X_np, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history5 = rnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "y_pred = rnn.predict(X_test, rnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = rnn.evaluateRNN(X_test, y_test, y_pred, rnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "rnn.plotTrainingHistory(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "input_shape = X_train.shape[1:]\n",
    "cnn_model = cnn.configModel(input_shape)\n",
    "history6 = cnn_model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)\n",
    "y_pred = cnn.predict(X_test, cnn_model)\n",
    "test_precision, test_recall, test_f1_score, test_loss, test_accuracy = cnn.evaluateCNN(X_test, y_test, y_pred, cnn_model)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1_score}')\n",
    "cnn.plotTrainingHistory(history6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
